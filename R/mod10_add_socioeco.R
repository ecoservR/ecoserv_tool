#######################################
### Worflow functions               ###
### for EcoservR                    ###
### Sandra Angers-Blondin           ###
### revised 09-08-2021              ###
#######################################


## The socioeconomic datasets are way too large to push to GitHub whole, and it would be wasteful to load the whole national dataset into memory anyway.

## Instead the socioeconomic module can be adapted to recognize which grid ref are needed, and only loads the relevant files.


## Once the package is installed with the lazy-load data in place in the inst/extdata folder, the actual path (user-specific) can be found with
# system.file("extdata/IMD", package = "ecoservR")
# we can therefore use list.files to get list of available tiles and only load those required (these are the only ones that will be actually loaded in memory) by using regex on tile names

#test <- list.files(system.file("extdata/IMD", package = "ecoservR"))

## MAJOR UPDATE Nov 2021: the extraction process was assigning the health values randomly across houses in each tile! Now fixed to order by TOID so this does not happen


#' Add socio-economic data
#'
#' This function adds population (UK Census 2011) and health (Index of Multiple Deprivation 2019) data into the basemap where people are living (domestic buildings). The resulting fields are housePop (average number of people per dwelling )

#' @param mm The mm object loaded in the environment. Needs to have undergone classification as population data are extracted into polygons classified as domestic buildings.
#' @param studyAreaBuffer The buffered study area generated during mod01 or reloaded when resuming a session.
#' @param projectLog The RDS project log file generated by the wizard app and containing all file paths to data inputs and model parameters
#' @return Saves a project_title_MM_classified_pop.RDS file to project folder
#' @export

add_socioeco <- function(mm = parent.frame()$mm,
                         studyAreaBuffer = parent.frame()$studyAreaBuffer,
                         projectLog = parent.frame()$projectLog){

   timeA <- Sys.time() # start time


   ## Extract the file paths and other info from project log ----------------------

   output_temp <- projectLog$output_temp
   title <- projectLog$title
   scratch_path <- file.path(output_temp, "ecoservR_scratch")
   if (!dir.exists(scratch_path)) dir.create(scratch_path)




   # Identify which tiles need loading ---------------------------------------

   if (is.null(names(mm))) stop("This function requires basemap tiles to be named with a grid reference. Run the add_grid_ref() function and retry.")

   tiles <- unique(substr(names(mm),1, 2))  # keep the first 2 character of map tile names, which corresponds to the 100 km x 100 km tiles used to store the socio-eco data

   tiles <- paste0("_",tiles)  # add an underscore to enable the pattern-matching in next step


   ## Search for the data in the package files, only keeping those with a relevant grid ref
   census_tiles <- list.files(system.file("extdata/census", package = "ecoservR"),
                              pattern = paste0(tiles, collapse = "|"),
                              full.names = TRUE)

   imd_tiles <- list.files(system.file("extdata/IMD", package = "ecoservR"),
                           pattern = paste0(tiles, collapse = "|"),
                           full.names = TRUE)


   if (length(census_tiles) == 0 | length(imd_tiles) == 0) stop("Could not find data for study area.")


   # Prepare basemap to receive and extract ----------------------------------

   # Create columns to receive data

   mm <- lapply(mm, function(x) mutate(x,
                                       housePop = NA_real_,
                                       health = NA_real_,
                                       riskgroup = NA_real_))

   # Create an index telling us which features are houses in each basemap tile

   houses <- lapply(mm, function(x) which(x$HabCode_B == "J360"))

   # Create their centroids as simple point data (if no house in a tile, returns empty geometry)
   centro <- mapply(function(x,y) sf::st_centroid(dplyr::select(x[y,], TOID)) %>%  # keeping toid so we can match to mm later
                       sf::st_as_sf(),
                    x = mm,
                    y = houses,
                    SIMPLIFY = FALSE)


   # IMD ---------------------------------------------------------------------

   message("Importing Index of Multiple Deprivation (2019) data...")

   imd <- lapply(imd_tiles, function(x) readRDS(x)) # read file
   imd <- do.call(rbind, imd)   # recombine

   imd <- checkcrs(imd, studyAreaBuffer) # make sure crs is the same

   # Clip to study area
   imd <- suppressWarnings({imd %>%
         sf::st_intersection(sf::st_geometry(studyAreaBuffer))
   })

   # Tidy up geometries
   imd <- checkgeometry(imd, "POLYGON")


   message("Extracting IMD data...")

   ## Use the house feature index and the centroids to query the data

   for (i in 1:length(centro)){

      if (nrow(centro[[i]]) == 0) {next} # skip iteration if no houses

      ## extract values in IMD layer that fall under each point

      # there is a problem where some house points fall outside of the extracted IMD (on margins of study area)
      # we need to add an extra subsetting index to not be caught out by extraction of different lengths
      within_imd <- lengths(sf::st_intersects(centro[[i]], imd)) > 0

      ## this version yielded values that couldn't be matched in order to the data
      # vals <- suppressWarnings({
      #    sf::st_intersection(centro[[i]][within_imd,], imd)$health
      # })

      ## New solution creates dataframe rather than vector, so later can order by toid
      vals <- suppressWarnings({
         sf::st_intersection(centro[[i]][within_imd,], imd) %>%   # gets the health data from imd polygons
         sf::st_drop_geometry()  # drops geom so we only deal with toid and health score
      })

      # add values into mm tile using indexing (only to the houses that actually had an intersection with IMD),
      # AND ordered by TOID on both sides so we get a perfect match

      mm[[i]][houses[[i]][within_imd], ][order(mm[[i]][houses[[i]][within_imd], ]$TOID),][["health"]] <- vals[order(vals$TOID), ]$health

   }

   rm(imd, imd_tiles)


   # Census ------------------------------------------------------------------

   # Census data of 2011
   message("Importing census (2011) data...")

   census <- lapply(census_tiles, function(x) readRDS(x)) # read file
   census <- do.call(rbind, census)  # recombine

   census <- checkcrs(census, studyAreaBuffer) # make sure CRS def is the same

   # Clip to study area
   census <- suppressWarnings({census %>%
         sf::st_intersection(sf::st_geometry(studyAreaBuffer))
   })

   # Tidy up geometries
   census <- checkgeometry(census, "POLYGON")

   message("Extracting census data...")
   ## Use the house feature index and the centroids to query the data

   for (i in 1:length(centro)){

      if (nrow(centro[[i]]) == 0) {next} # skip iteration if no houses

      # extract values in layer that fall under each point

      # there is a problem where some house points fall outside of the extracted data (on margins of study area)
      # we need to add an extra subsetting index to not be caught out by extraction of different lengths
      within_census <- lengths(sf::st_intersects(centro[[i]], census)) > 0


      ## old way
      # vals <- suppressWarnings({
      #    sf::st_intersection(centro[[i]][within_census,], census)
      # })

      ## New solution creates dataframe rather than vector, so later can order by toid
      vals <- suppressWarnings({
         sf::st_intersection(centro[[i]][within_census,], census) %>%   # gets therisk and housepop data from census polygons
            sf::st_drop_geometry()  # drops geom so we only deal with toid and health score
      })

      # add values into mm tile using indexing

      mm[[i]][houses[[i]][within_census], ][order(mm[[i]][houses[[i]][within_census], ]$TOID),][["riskgroup"]] <- vals[order(vals$TOID), ]$riskgroup
      mm[[i]][houses[[i]][within_census], ][order(mm[[i]][houses[[i]][within_census], ]$TOID),][["housePop"]] <- vals[order(vals$TOID), ]$housePop

   }

   rm(census, census_tiles, centro, houses, vals, i)


   # Finish and save ---------------------------------------------------------

   # Save to disk

   saveRDS(mm, file.path(output_temp, paste0(title, "_MM_classified_pop.RDS")))


   # Update the project log with the information that map was updated

   projectLog$last_success <- "MM_classified_pop.RDS"

   timeB <- Sys.time() # stop time

   # add performance to log
   projectLog$performance[["add_socioeco"]] <- as.numeric(difftime(
      timeB, timeA, units="mins"
   ))

   updateProjectLog(projectLog) # save revised log


   message(paste0("Finished adding socio-economic data. Process took ",
                  round(difftime(timeB, timeA, units = "mins"), digits = 1),
                  " minutes."))



   # Return mm to environment
   return({
      invisible({
         mm <<- mm
         projectLog <<- projectLog
      })
   })

} # end of function
